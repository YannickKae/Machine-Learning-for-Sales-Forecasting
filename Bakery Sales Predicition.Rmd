# Data Preparation for Neural Network 
  # prepare environment, load libraries
  # data import 
  # recode variables into dummy variables 
  
```{r}
# load libraries
pkgs <- c("readr", "fastDummies", "reticulate", "ggplot2", "Metrics")

for (pkg in pkgs) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

# data import 
neural_network_test <- NN_daten_final

# recode variables into dummy variables 
dummy_list_all <- c("Wochentag")
neural_network_dummies = dummy_cols(neural_network_test, dummy_list_all) 
names(neural_network_dummies)

# definition of lists for each dummy
dummies <- c("Wochentag_Montag", "Wochentag_Dienstag", "Wochentag_Mittwoch", "Wochentag_Donnerstag", "Wochentag_Freitag", "Wochentag_Samstag", "Wochentag_Sonntag")

# selection of feature variables and label variable

# selection of the features (independent variables used to predict the dependent)
features <- c("Kreuzfahrt_Anzahl", "Verbraucherpreisindex", "Bewoelkung", "Temperatur.y", "Windgeschwindigkeit.y", "Arbeitslose", "Bruttoverdienste", "Gaesteankuenfte", "Insolvenzen", dummies, "KielerWoche", "Heimspiel_KSV", "Kreuzfahrt_Anlauf", "Heimspiel_THW", "Feiertag", "Ferien")

# selection of the label (dependent variable)
labels <- "W5"

# look at data 
str(neural_network_dummies)

# set random counter to a fixed value 
set.seed(1)

# shuffle data set to get a random order 
new_row_oder <- sample(nrow(neural_network_dummies))
neural_network_dummies <- neural_network_dummies[new_row_oder, ]

# assign each row number in dataset randomly to one of the three groups of datasets 
# probability of of being in one of the groups results in corresponding group sizes 
assignment <- sample(1:3, size = nrow(neural_network_dummies), prob = c(.7, .2, .1), replace = TRUE)

# create training, validation and test data for features and labels 
training_features <- neural_network_dummies[assignment == 1, features]
training_labels <- neural_network_dummies[assignment == 1, labels]

validation_features <- neural_network_dummies[assignment == 2, features]
validation_labels <- neural_network_dummies[assignment == 2, labels]

test_features <- neural_network_dummies[assignment == 3, features]
test_labels <- neural_network_dummies[assignment == 3, labels]
```

# Neural Network 

```{python}
# Importieren von libraries 

import sys 
import tensorflow 
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization, Dropout 
from tensorflow.keras.optimizers import Adam 

# The argument "input_shape" for the definition of the input layer must include the number input variables (features) used for the model. To automatically calculate this number, we use the  function `r.training_features.keys()`, which returns the list of variable names of the dataframe `training_features`. Then, the function `len()` returns the length of this list of variable names (i.e. the number of variables in the input).
model = Sequential([InputLayer(input_shape=(len(r.training_features.keys()), )), BatchNormalization(), Dense(10, activation='relu'), Dropout(.2), Dense(4, activation='relu'), Dense(1)])

# Zusammenfassung Form des Modells 
model.summary()
```

```{python}
import pandas as pd
# Schätzung des neuronalen Netzes 

# Definition Kosten-(Loss-)Funktion und Optimierungsfunktion mit Hyperparametern 
model.compile(loss="mse", optimizer=Adam(learning_rate=0.001))

# Schätzung des Modells 
history = model.fit(r.training_features, r.training_labels, epochs=1000, validation_data = (r.validation_features, r.validation_labels), verbose="auto")

# Speichern des geschätzten Modells 
model.save("python_model.h5")
```

# Auswertung der Modelloptimierung
```{r}
# graphische Ausgabe der Modelloptimierung 
# create data 
data <- data.frame(val_loss = unlist(py$history$history$val_loss), loss = unlist(py$history$history$loss))

# plot 
ggplot(data[-(1:10),]) + geom_line(aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) + geom_line(aes(x=1:length(loss), y=loss, colour = "Training Loss" )) + scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red")) + labs(title="Loss Function Values During Optimization") + xlab("Iteration Number") + ylab("Loss") 
```

# Laden des gespeicherten neuronalen Netzes 
```{python}
model = tf.keras.models.load_model("python_model.h5")
``` 

# Auswertung der Schätzergebnisse 
```{r}
# Schätzung der normierten Preise für die Trainins- und Testdaten 
training_predictions <- py$model$predict(training_features)
validation_predictions <- py$model$predict(validation_features)

# Vergleich der Gütekriterien für die Trainings- und Testdaten 
cat(paste0("MAPE on the Training Data:\t", format(smape(training_labels[[1]], training_predictions)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(smape(validation_labels[[1]], validation_predictions)*100, digits=3, nsmall=2)))
``` 
```{r}
vorhersage <- py$model$predict(vorhersage_features)
```

```{r}
# Graphischer Vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten 

# Zusammenstellung der Daten für die Plots 
data_train <- data.frame(prediction = training_predictions/1000, actual = training_labels[[1]]/1000)
data_test <- data.frame(prediction = validation_predictions/1000, actual = validation_labels[[1]]/1000)

# Plot der Ergebnisse der Trainingsdaten 
ggplot(data_train[1:100,]) + geom_line(aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) + geom_line(aes(x=1:length(actual), y=actual, colour = "Actual Values" )) + scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) + labs(title="Predicted and Actual Values for the Training Data") + xlab("Case Number") + ylab("Price in 1.000 USD") 

# Plot der Ergebnisse der Validierungsdaten 
ggplot(data_test[1:100,]) + geom_line(aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) + geom_line(aes(x=1:length(actual), y=actual, colour = "Actual Values" )) + scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) + labs(title="Predicted and Actual Values for the Test Data") + xlab("Case Number") + ylab("Price in 1.000 USD") 

```

```{r}
# Vorhersage für einen einzelnen Fall 
cat(paste0("Vorhergesagter Preis:\t", round(validation_predictions[100])))
cat(paste0("\nTatsächlicher Preis:\t", validation_labels[[1]][100]))

```
